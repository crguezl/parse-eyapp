
=head1 INTRODUCTION TO PARSING WITH Parse::Eyapp

Parsing is the activity of producing a syntax tree
from an input stream. The program example in the synopsis 
section shows an example of a translation scheme. 
It translates infix arithmetic expressions like 

   a = 2 * 3 + 4 * b

into postfix expressions like 

   a 2 3 * 4 b * + =

The program contains a context free eyapp grammar defining the language 
of arithmetic infix expressions. A context free grammar
is a mathematical device to define languages. To better see the grammar
for the example above we have to eliminate the semantic 
actions (We call semantic actions to the sections containing Perl code).
This can be done calling C<eyapp> with options C<-vc>:

  $ eyapp -vc Postfix.eyp 
  %token NUM =/([0-9]+(?:\.[0-9]+)?)/ 
  %token VAR =/([A-Za-z][A-Za-z0-9_]*)/ 
  %right '=' 
  %left '-' '+' 
  %left '*' '/' 
  %left NEG 

  %%

  line:
        exp 
  ;
  exp:
        NUM
      | VAR
      | VAR '=' exp
      | exp '+' exp
      | exp '-' exp
      | exp '*' exp
      | exp '/' exp
      | '-' exp %prec NEG
      | '(' exp ')'  
  ;

  %%


A grammar generates a language. A grammar is defined by a set of production rules. A production rule
has two components: a left hand side which is a I<syntactic variable> or I<non terminal> and a right hand side
which is a phrase made of syntactic variables and terminals. The left hand side (I<lhs>) and the right
hand side (I<rhs>) are usually separated by an arrow like in:

                                    exp -> VAR = exp

A note: the production rule

                        line: exp <+ ';'>

is not really a production rule but an abbreviation for two productions. It stands for:

                        line : exp
                             | line ';' exp
                        ;


A I<terminal> or I<token> never appears on the left hand side of a production rule.
The phrases of the language are those obtained 
successively applying the production rules of the grammar until no more rules can be applied.
The successive substitutions must start from the C<start> symbol of the grammar (C<line> in
the example). Such legal
sequence of substitutions is known as a I<derivation>. The following is an example of a
legal derivation (the big arrow C<=E<gt>> is read I<derives>):

  line => exp => VAR = exp => VAR = exp + exp => VAR = exp + NUM => VAR = VAR + NUM

thus the phrase C<VAR = VAR + NUM> belongs to the language generated by the former grammar.
A derivation like can be seen as a tree. For instance, the former derivation is equivalent (has 
the same information) than the tree:

                             +----+
                             |line|
                             +----+
                                |
                              +---+
                              |exp|
                              +---+
                    .-----.-----^-----.
                  +---+ +---+        +---+
                  |VAR| | = |        |exp|
                  +---+ +---+        +---+
                                 .-----+-----.
                               +---+ +---+ +---+
                               |exp| | + | |exp|
                               +---+ +---+ +---+
                                 |           |
                               +---+       +---+
                               |VAR|       |NUM|
                               +---+       +---+

which can be written more succinctly:

                        line(exp(VAR, '=', exp(exp(VAR), '+',  exp(NUM))))


Such a tree is called a I<syntax tree> for the input C<VAR = VAR + NUM>.
A grammar is said to be I<ambiguous> if there are phrases in the generated language that have
more than one syntax tree. The grammar in the synopsis example is ambiguous. Here is an alternative
tree for the same phrase C<VAR = VAR + NUM>:

                                    +----+
                                    |line|
                                    +----+
                                       |
                                     +---+
                                     |exp|
                                     +---+
                            .----------^-----.-----.
                          +---+            +---+  +---+
                          |exp|            | + |  |exp|
                          +---+            +---+  +---+
                      .-----+-----.                 |
                    +---+ +---+ +---+             +---+
                    |VAR| | = | |exp|             |NUM|
                    +---+ +---+ +---+             +---+
                                  |
                                +---+
                                |VAR|
                                +---+

or

                        line(exp(exp(VAR, '=', exp(VAR)), '+', exp(NUM)))

Parsers created by C<eyapp> do not deal directly with the input. Instead they expect the input
to be processed by a I<lexical analyzer>. The lexical analyzer parses the input and produces
the next token. A I<token> is a pair. The first component is the name of the token (like C<NUM>
or C<VAR>) and the second is its attribute (i.e. the information associated with the token, like 
that the value is C<4> for a C<NUM> or the identifier is C<temperature> for a
C<VAR>). Tokens are usually defined using regular expressions. Thus the token 
C<NUM> is characterized by C</[0-9]+(?:\.[0-9]+)?/> and the token
C<VAR> by C</[A-Za-z][A-Za-z0-9_]*/>. The L<eyapp> compiler 
automatically generates a lexical analyzer from
your token definitions. The tokens C<NUM> and C<VAR> were defined using the C<%token> directives:

  %token NUM = /([0-9]+(?:\.[0-9]+)?)/
  %token VAR = /([A-Za-z][A-Za-z0-9_]*)/

The order in which the tokens are defined is important. The input will be matched 
against the regular expression for C<NUM> before the regular expression for C<VAR>
is tried, and all the literal tokens that appear between quotes inside the body of the grammar,
like C<'+'> or C<'->, are tried before any explicitly defined token.

You can, alternatively, define the lexical analyzer explicitly. There are many ways to do it.
Here is an example of a 
definition of a lexical analyzer using the C<%lexer> directive::

  %lexer  {
    m{\G[ \t]*}gc;
    m{\G(\n)+}gc                    and $self->tokenline($1 =~ tr/\n//);
    m{\G([0-9]+(?:\.[0-9]+)?)}gc    and return ('NUM',   $1);
    m{\G([A-Za-z_][A-Za-z0-9_]*)}gc and return ('VAR',   $1);
    m{\G(.)}gc                      and return ($1,      $1);
  }

The C<%lexer> directive is followed by the code defining the lexical analyzer.
When called, the variable C<$_> is an alias of the input. 
The input can also be set and accessed via the C<input> method of the C<$parser> object. 

To catch the next pattern we use the anchor C<\G>.
The C<\G> anchor matches at the point where the previous C</g> match left off. 
Normally, when a scalar C<m{}g> match fails, the match position is reset and
C<\G> will start matching at the beginning of the string.
The C<c> option causes the match position to be retained following an unsuccessful match.
The couple C<('',undef)> which signals the end of the input is automatically inserted by 
C<eyapp>.

C<Parse::Eyapp> analyzes your grammar and produce a LALR parser.
Actually the SYNOPSIS example is more than a context free grammar: 
is a I<translation scheme>. A I<translation scheme> 
scheme is a context free grammar where the right hand sides of the productions 
have been augmented with semantic actions (i.e. with chunks of Perl code):

                                A -> alpha { action(@_) } beta

The analyzer generated by Eyapp executes C<{ action(@_) }> after all the semantic actions
associated with C<alpha> have been executed and before the execution of any of the semantic 
actions associated with C<beta>. 

Notice that ambiguous grammars produce ambiguous translation schemes: 
since a phrase may have two syntactic
trees it will be more than one tree-traversing and consequently more than one 
way to execute the embedded semantic actions. Certainly different execution
orders will usually produce different results. Thus, syntactic ambiguities translate
onto semantic ambiguities. That is why it is important to resolve all the 
ambiguities and conflicts that may arise in our grammar. This is the function 
of the C<%left> and C<%right> declarations on the header section:

      %right  '='     # Lowest precedence
      %left   '-' '+' # + and - have more precedence than = Disambiguate a-b-c as (a-b)-c
      %left   '*' '/' # * and / have more precedence than + Disambiguate a/b/c as (a/b)/c
      %left   NEG     # Disambiguate -a-b as (-a)-b and not as -(a-b)

Priority can be assigned to tokens by using the C<%left> and C<%right> declarations. I<Tokens in
lines below have more precedence than tokens in line above>. 
How it works when two tokens are declared in the same line?
Consider the phrase C<NUM - NUM - NUM>. It will be interpreted
as C<(NUM - NUM) - NUM> if the token C<'-'> is declared C<%left '-'> and 
will be interpreted as C<NUM - (NUM - NUM)>  if the token C<'-'> is declared C<%right '-'>.
The idea  behind this notation is this: 
I<Any ambiguity can be seen as a parenthesizing problem>. By saying C<'-'> is left
we are saying we  prefer between the two trees in dispute the one
that is deeper to the left:

                                       +---+
                                       |exp|
                                       +---+
                                .--------^--.-----.
                              +---+       +---+ +---+
                              |exp|       | - | |exp|
                              +---+       +---+ +---+
                          .-----+-----.           |
                        +---+ +---+ +---+       +---+
                        |exp| | - | |exp|       |NUM|
                        +---+ +---+ +---+       +---+
                          |           |
                        +---+       +---+
                        |NUM|       |NUM|
                        +---+       +---+

By saying C<'-'> is right we are saying we  prefer between the two trees in dispute the one
that is deeper to the right:

                                        +---+
                                        |exp|
                                        +---+
                              .-----.-----^-----.
                            +---+ +---+       +---+
                            |exp| |MIN|       |exp|
                            +---+ +---+       +---+
                              |           .-----+-----.
                            +---+       +---+ +---+ +---+
                            |NUM|       |exp| |MIN| |exp|
                            +---+       +---+ +---+ +---+
                                           |           |
                                         +---+       +---+
                                         |NUM|       |NUM|
                                         +---+       +---+


By giving token C<'+'> more precedence than token C<'='> we solve the ambiguity in
C<VAR = VAR + NUM> in favor of C< VAR = (VAR + NUM)>.

Since I<priority means earlier evaluation>
and the evaluation by L<eyapp> of semantic actions is bottom up, I<the deeper the associated subtree the higher
the priority>.

In a translation scheme each symbol occurrence has an I<associated attribute>.
The embedded actions modify the attributes associated with the symbols of the grammar:

                        A -> alpha { action(@_) } beta

I<Each symbol on the right hand side
of a production rule has an associated scalar attribute>. In C<eyapp> the attributes of the symbol
to the left of C<action> are passed as arguments to C<action> (in the example, those of C<alpha>). 
These arguments are preceded by a reference to the syntax analyzer object.
There is no way inside an ordinary C<eyapp> program for an intermediate C<action> to 
access the attributes of the symbols
on its right, i.e. those associated with the symbols of C<beta>. This restriction is lifted 
if you  use the C<%metatree> directive to build a full translation scheme. 
See 
L<Parse::Eyapp::translationschemestut>
to know more about full translation schemes.

Actions on the 
right hand side counts as symbols and so they can be referenced by its positional argument
in later actions in the same production rule. For intermediate actions, the value returned by the C<action> is 
the attribute associated with such action. For an action at the end of the rule:

                                A -> alpha { lastaction(@_) } 

the returned value constitutes the attribute of the left hand side of the rule (the
attribute of C<A> in this case). The action at the end of the right hand side is 
called the I<action associated with the production rule>. When no explicit action
has been associated with a production rule the I<default action> applies. In C<Parse::Eyapp>
the programmer can define what is the default action through the C<%defaultaction> directive: 


  %defaultaction { "$left $right $op"; }

A very special
action is "I<build the node associated with this production rule>" which
is performed by the C<YYBuildAST> method of the parser object:

                %default action { goto &Parse::Eyapp::Driver::YYBuildAST }

The C<%tree> directive is an abbreviation for this and has the effect of building an abstract syntax tree
for the input. See the grammar C<eyappintro/Tree.eyp>:

  %{
    use Data::Dumper;
    $Data::Dumper::Indent = 1;
  %}

  %token NUM = /([0-9]+(?:\.[0-9]+)?)/
  %token VAR = /([A-Za-z][A-Za-z0-9_]*)/

  %right  '='
  %left   '-' '+'
  %left   '*' '/'
  %left   NEG

  %defaultaction {  goto &Parse::Eyapp::Driver::YYBuildAST }

  %%
  line: exp  { print Dumper($_[1]) }
  ;

  exp:        %name NUM      NUM
          |   %name VAR      VAR
          |   %name ASSIGN   VAR '=' exp
          |   %name PLUS     exp '+' exp
          |   %name MINUS    exp '-' exp
          |   %name TIMES    exp '*' exp
          |   %name DIV      exp '/' exp
          |   %name MINUS    '-' exp %prec NEG
          |   %name PAREN   '(' exp ')'
  ;

  %%


The call to 

       Parse::Eyapp->new_grammar( # Create the parser package/class
          input=>$grammar,
          classname=>"Calc", # The name of the package containing the parser
        );

compiles C<$grammar> and 
produces a new class C<Calc> containing
a LALR parser for such grammar. The call

                          $parser = Calc->new()

creates a parser object for the language generated by C<$grammar>.
Using the  C<YYParse> of the parser object:

        $self->YYParse( yylex => \&_Lexer, yyerror => \&_Error, )

C<YYParse> is called with arguments a reference to the lexical analyzer and 
a reference to the error diagnostic subroutine C<_Error>. Such subroutine
will be called by C<YYParse> when an error occurs. Is therefore convenient
to give a meaningful diagnostic:

    sub _Error { 
      die "Syntax error near "
      .($_[0]->YYCurval?$_[0]->YYCurval:"end of file")."\n" 
    }

The parser method C<YYCurval> returns the value of the current token.
A more accurate error diagnostic subroutine can be obtained if  
the lexical analyzer is modified so that
tokens keep the line number where they start (i.e. the token 
is a pair C<(TOKENNAME, [ ATTRIBUTE, LINENUMBER])>. In such case 
the C<_Error> subroutine can be rewritten as:

  sub _Error {
    my($token)=$_[0]->YYCurval;
    my($what)= $token ? "input: '$token->[0]' in line $token->[1]" : "end of input";
    my @expected = $_[0]->YYExpect();
    my $expected = @expected? "Expected one of these tokens: '@expected'":"";

    croak "Syntax error near $what. $expected\n";
  }

The C<YYExpect> method returns the set of tokens that were expected when
the error occurred.

The input in 

                $parser->YYData->{INPUT} 

is then analyzed by C<YYParse> and 
an abstract syntax tree is built. The tree rooted on a C<Parse::Eyapp::Node>
can be displayed using the method C<str>:

                    local $Parse::Eyapp::Node::INDENT=2;
                    print "Syntax Tree:",$t->str;

The following is the description of the syntax tree produced by the call C<$t-E<gt>str> for the 
list of expressions C<"2*-3+b*0;--2\n";>:

  pl@nereida:~/LEyapp/examples$ synopsis.pl
  Syntax Tree:
  EXPRESSION_LIST(
    PLUS(
      TIMES(
        NUM(
          TERMINAL[2]
        ),
        UMINUS(
          NUM(
            TERMINAL[3]
          )
        ) # UMINUS
      ) # TIMES,
      TIMES(
        VAR(
          TERMINAL[b]
        ),
        NUM(
          TERMINAL[0]
        )
      ) # TIMES
    ) # PLUS,
    UMINUS(
      UMINUS(
        NUM(
          TERMINAL[2]
        )
      ) # UMINUS
    ) # UMINUS
  ) # EXPRESSION_LIST

Did you notice that the C<TERMINAL> nodes appear I<decorated> with its attribute?
This is because each time the C<Parse::Eyapp::Node> method C<str>
visits a node checks if the node has a method C<info> (i.e. C<$node-E<gt>can(info)>).
If so, the C<info> method is called and the string returned is concatenated
in the description string. This is the reason for these three lines at the beginning of the
L</SYNOPSIS> example:

                    sub TERMINAL::info {
                      $_[0]{attr}
                    }

C<Parse::Eyapp> not only gives support to parsing
but to later phases of the translation process: 
tree transformations and
scope analysis (scope analysis is the task to find which definition
applies to an use of an object in the source). The program in the synopsis 
section shows an example of a tree transformation
specification. Tree transformations are specified using
a language called I<Tree regular expressions>.
The transformation object is created by the 
constructor C<Parse::Eyapp::Treeregexp-E<gt>new>.

  my $p = Parse::Eyapp::Treeregexp->new( STRING => q{
      { #  Example of support code
        my %Op = (PLUS=>'+', MINUS => '-', TIMES=>'*', DIV => '/');
      }
      constantfold: /TIMES|PLUS|DIV|MINUS/:bin(NUM($x), NUM($y))
        => {
          my $op = $Op{ref($bin)};
          $x->{attr} = eval  "$x->{attr} $op $y->{attr}";
          $_[0] = $NUM[0];
        }
      uminus: UMINUS(NUM($x)) => { $x->{attr} = -$x->{attr}; $_[0] = $NUM }
      zero_times_whatever: TIMES(NUM($x), .) and { $x->{attr} == 0 } => { $_[0] = $NUM }
      whatever_times_zero: TIMES(., NUM($x)) and { $x->{attr} == 0 } => { $_[0] = $NUM }
    },
  );

The set of transformations specified in the example
are

=over 2 

=item * 

The transformation C<constantfold> produces
I<constant folding> i.e. trees of expressions
like C<3*2+4> are reduced to the tree for C<10> 

      { #  Example of support code
        my %Op = (PLUS=>'+', MINUS => '-', TIMES=>'*', DIV => '/');
      }
      constantfold: /TIMES|PLUS|DIV|MINUS/:bin(NUM($x), NUM($y))
        => {
          my $op = $Op{ref($bin)};
          $x->{attr} = eval  "$x->{attr} $op $y->{attr}";
          $_[0] = $NUM[0];
        }

Here C<constantfold> is the name of the transformation. 
The treeregexp compiler will produce an object C<$constantfold>
implementing the transformation. After the name
comes the tree pattern: 

          /TIMES|PLUS|DIV|MINUS/:bin(NUM($x), NUM($y))

It matches any subtree rooted in any node belonging to one of 
these classes: C<TIMES> or C<PLUS> or C<DIV> or C<MINUS> that has
two children belonging to the C<NUM> class. The Perl code after the big arrow
is executed on any matching subtree. We can refer to the root of the subtree
using the variable C<$bin>. We can also refer to the child of the first C<NUM> node
using C<$x>. In the same way C<$y> refers to the child of the second C<NUM>
node. Since there are two C<NUM> nodes in the pattern, we refer to them inside
the transformation part using the array C<@NUM>:

                         $_[0] = $NUM[0];

The action uses and C<eval> and the hash C<%Op> to compute the 
corresponding reduction of the two nodes. The hash C<%Op> was defined in a previous
section containing support code. You can insert in any place of a treeregexp 
program such support code by surrounding it with curly brackets.
The subtree that matched (that is in C<$_[0]>) is substituted
by its left child:

                         $_[0] = $NUM[0];


=item * 

The transformations C<zero_times_whatever>
and C<whatever_times_zero> produce
the simplification of trees corresponding
to multiplications by zero. 
Trees for expressions like C<(a+b)*0>
or C<0*(b-4)>  are reduced 
to the tree for 0.

  zero_times_whatever: TIMES(NUM($x), .) and { $x->{attr} == 0 } => { $_[0] = $NUM }

Here C<zero_times_whatever> is the name of the transformation.
The pattern C<TIMES(NUM($x), .)> matches any C<TIMES> node 
with two children and whose first child belongs to the C<NUM>
class. The dot matches any subtree, indicating that we don't care what
sort of tree the right child is. The third component

                   { $x->{attr} == 0 }

is the semantic pattern. If both the shape pattern and the semantic pattern
apply the action after the arrow is applied. The subtrees
is substituted by its left child.

=item *

The transformation C<uminus> simplifies
the tree for unary minus of constant expressions.

      uminus: UMINUS(NUM($x)) => { $x->{attr} = -$x->{attr}; $_[0] = $NUM }

It matches trees rooted in a C<UMINUS> node whose only child is a C<NUM> node.
In such case the sign of the number that is the attribute of the C<TERMINAL> node 
is changed and the tree is substituted by its single child.

=back

The call

                  $p->generate(); 

compiles the transformation specification producing
a set of transformations C<$constantfold>, 
C<$zero_times_whatever>, C<whatever_times_zero> and  C<$uminus>.
Transformations are C<Parse::Eyapp::YATW> objects. The list variable
C<@all> refer to the whole set of C<Parse::Eyapp::YATW> 
transformations.

The nodes of the abstract syntax tree are objects. The class
(C<NUM>, C<TIMES>, C<UMINUS>, etc.) defines the type of node.
All node classes inherit from the class C<Parse::Eyapp::Node>.
C<Parse::Eyapp::Node> provides a set of methods to manipulate nodes.
Among these methods are C<str>, C<m> and C<s>. The C<m> and C<s> methods 
resemble the matching and substitution operators for regular
expressions. But instead of regular expressions they work 
with tree transformations or C<treeregexp>s or, more
precisely with C<Parse::Eyapp::YATW> objects.
By calling:

                          $t->s($uminus);

subtrees like 

                  UMINUS(UMINUS(NUM(TERMINAL[2])))

are simplified to

                                   NUM(TERMINAL[2])

The call to

                           $t->s(@all);

applies the whole set of transformations. The transformations in C<@all> 
are iteratively
applied to the tree C<$t> until no transformation succeeds: Yes, that means that
a inappropriate set of transformations my hang your program.

Thus, the former syntax tree for C<"2*-3+b*0;--2\n";> 
becomes:

  EXPRESSION_LIST(NUM(TERMINAL[-6]),NUM(TERMINAL[2]))

The analyzer has been able to optimize - at compile time -
the computation of these two expressions

                    2*-3+b*0;
                    --2

reducing them to the computation of:

                     -6;
                      2

